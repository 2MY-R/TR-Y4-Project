{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9a2596c0290cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:55:18.996229Z",
     "start_time": "2025-03-06T17:55:18.967872Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "from PIL import Image\n",
    "from detectron2.structures import BoxMode\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from matplotlib import image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from natsort import natsorted\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3afc2b5042a9e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:40:10.760124Z",
     "start_time": "2025-03-06T18:40:10.744597Z"
    }
   },
   "outputs": [],
   "source": [
    "class tiffSegmentation:\n",
    "    def __init__(self, model_file, input_file, output_dir, output_num):\n",
    "        self.model_file = model_file\n",
    "        self.input_file = input_file\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self.output_num = output_num\n",
    "        \n",
    "        self.img_dataset = cv2.imreadmulti(input_file)[1] \n",
    "        self.img = self.img_dataset[0]\n",
    "\n",
    "        if output_num == None:\n",
    "            self.output_num = len(self.img_dataset)\n",
    "        else:\n",
    "            output_num = output_num\n",
    "        \n",
    "        self.classes = [\"amoeba\", \"yeast\"]\n",
    "        self.predictor = self.modelPrep()\n",
    "\n",
    "    def phaseSeg(self):\n",
    "        \n",
    "        if os.path.exists(self.output_dir):  # if folder phase masks already exists in output directory remakes\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        os.makedirs(self.output_dir)\n",
    "        \n",
    "        for i,img in enumerate(self.img_dataset[::2][:self.output_num]):\n",
    "            self.img = img\n",
    "            \n",
    "            sys.stdout.write(f'\\rSegmenting image {i + 1} / {len(self.img_dataset)}')\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "            image_filename = \"phase_\" + str(i)\n",
    "            \n",
    "            outputs = self.predictor(self.imgPrep())  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "            # input_images_directory = Dataset\n",
    "\n",
    "            class_masks = {class_name: torch.zeros_like(outputs[\"instances\"].pred_masks[0], dtype=torch.int16, )\n",
    "                           for class_name in self.classes}\n",
    "\n",
    "        # Assign a unique integer label to each object in the mask\n",
    "            for i, pred_class in enumerate(outputs[\"instances\"].pred_classes):\n",
    "                class_name = self.classes[pred_class]\n",
    "                instance_mask = outputs[\"instances\"].pred_masks[i]\n",
    "                class_masks[class_name] = torch.where(instance_mask,\n",
    "                                                      torch.tensor(i + 1, dtype=torch.float32),\n",
    "                                                      class_masks[class_name].to(dtype=torch.float32))\n",
    "                class_masks[class_name] = class_masks[class_name].to(dtype=torch.int16)\n",
    "    \n",
    "            for class_name, class_mask in class_masks.items():\n",
    "                class_mask_np = class_mask.cpu().numpy()\n",
    "                image_name = image_filename + f'_{class_name}.tif'\n",
    "    \n",
    "                output_path = os.path.join(self.output_dir, class_name)\n",
    "                \n",
    "                os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "                Image.fromarray(class_mask_np.astype(np.uint16)).save(Path(output_path) / image_name)\n",
    "    \n",
    "    def modelPrep(self):\n",
    "        from detectron2 import model_zoo\n",
    "        from detectron2.engine import DefaultPredictor\n",
    "        from detectron2.config import get_cfg\n",
    "        \n",
    "        \n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training\n",
    "        cfg.MODEL.WEIGHTS = self.model_file\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  # Default is 512, using 256 for this dataset.\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # We have 200 classes.\n",
    "        cfg.TEST.DETECTIONS_PER_IMAGE = 300\n",
    "\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5# set a custom testing threshold\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "        return predictor\n",
    "    \n",
    "    def imgPrep(self):\n",
    "        im = np.stack([self.img,self.img,self.img])\n",
    "        return im.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240c60900d2dd797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:40:11.549561Z",
     "start_time": "2025-03-06T18:40:11.543345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Image_repo\\no_yeat_1\\TiffStack\\no_yeat_1_MMStack_Pos0.ome.tif\n",
      "F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Image_repo\\no_yeat_1\\TiffStack\\no_yeat_1_MMStack_Pos0_1.ome.tif\n",
      "F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Image_repo\\no_yeat_1\\TiffStack\\no_yeat_1_MMStack_Pos0_2.ome.tif\n",
      "F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Image_repo\\no_yeat_1\\TiffStack\\no_yeat_1_MMStack_Pos0_3.ome.tif\n"
     ]
    }
   ],
   "source": [
    "folder_path = Path(r\"F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Image_repo\\no_yeat_1\\TiffStack\")\n",
    "for file in folder_path.iterdir():\n",
    "    if file.is_file():\n",
    "        print(Path.joinpath(folder_path, file.name))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0701647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Research\\SavedSegs\\tiffPhaseSegs_NoYeast_0\n",
      "Segmenting image 255 / 510F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Research\\SavedSegs\\tiffPhaseSegs_NoYeast_1\n",
      "Segmenting image 255 / 510F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Research\\SavedSegs\\tiffPhaseSegs_NoYeast_2\n",
      "Segmenting image 255 / 510F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Research\\SavedSegs\\tiffPhaseSegs_NoYeast_3\n",
      "Segmenting image 135 / 270"
     ]
    }
   ],
   "source": [
    "folder_path = Path(r\"F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Image_repo\\no_yeat_1\\TiffStack\") # folder with tiffstacks\n",
    "for i, file in enumerate(folder_path.iterdir()): # iterates through each tiff stack in folder\n",
    "    if file.is_file():\n",
    "\n",
    "        tiffstack_path = Path.joinpath(folder_path, file.name)\n",
    "        model_path = r'F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Model_v3\\model_final.pth' #model used to segment images\n",
    "\n",
    "        segDir = 'tiffPhaseSegs' + f'_NoYeast_{i}' #name of output directory\n",
    "\n",
    "        # Name or version of your current output segmentation directoryu7\n",
    "        output_path = r'F:\\Work\\UNI\\ResProj\\TR-Y4-Project\\Research\\SavedSegs' # location of masks folders \n",
    "\n",
    "        output_path = os.path.join(output_path, segDir)\n",
    "\n",
    "        print(output_path)\n",
    "    \n",
    "        my_seg = tiffSegmentation(model_path, tiffstack_path, output_path, output_num=None) # instance of class used for tiff segementation\n",
    "\n",
    "        my_seg.phaseSeg() #starts segmentation after intialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce607ca13906d3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
