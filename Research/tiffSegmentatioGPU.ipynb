{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9a2596c0290cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:55:18.996229Z",
     "start_time": "2025-03-06T17:55:18.967872Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "from PIL import Image\n",
    "from detectron2.structures import BoxMode\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from matplotlib import image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from natsort import natsorted\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afc2b5042a9e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:40:10.760124Z",
     "start_time": "2025-03-06T18:40:10.744597Z"
    }
   },
   "outputs": [],
   "source": [
    "class tiffSegmentation:\n",
    "    def __init__(self, model_file, input_file, output_dir, output_num):\n",
    "        self.model_file = model_file\n",
    "        self.input_file = input_file\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self.output_num = output_num\n",
    "        \n",
    "        self.img_dataset = cv2.imreadmulti(input_file)[1] \n",
    "        self.img = self.img_dataset[0]\n",
    "\n",
    "        if output_num == None:\n",
    "            self.output_num = len(self.img_dataset)\n",
    "        else:\n",
    "            output_num = output_num\n",
    "        \n",
    "        self.classes = [\"amoeba\", \"yeast\"]\n",
    "        self.predictor = self.modelPrep()\n",
    "\n",
    "    def phaseSeg(self):\n",
    "        \n",
    "        if os.path.exists(self.output_dir):  # if folder phase masks already exists in output directory remakes\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        os.makedirs(self.output_dir)\n",
    "        \n",
    "        for i,img in enumerate(self.img_dataset[::2][:self.output_num]):\n",
    "            self.img = img\n",
    "            \n",
    "            sys.stdout.write(f'\\rSegmenting image {i + 1} / {len(dataset)}')\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "            image_filename = \"phase_\" + str(i)\n",
    "            \n",
    "            outputs = self.predictor(self.imgPrep())  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "            # input_images_directory = Dataset\n",
    "\n",
    "            class_masks = {class_name: torch.zeros_like(outputs[\"instances\"].pred_masks[0], dtype=torch.int16, )\n",
    "                           for class_name in classes}\n",
    "\n",
    "        # Assign a unique integer label to each object in the mask\n",
    "            for i, pred_class in enumerate(outputs[\"instances\"].pred_classes):\n",
    "                class_name = self.classes[pred_class]\n",
    "                instance_mask = outputs[\"instances\"].pred_masks[i]\n",
    "                class_masks[class_name] = torch.where(instance_mask,\n",
    "                                                      torch.tensor(i + 1, dtype=torch.float32),\n",
    "                                                      class_masks[class_name].to(dtype=torch.float32))\n",
    "                class_masks[class_name] = class_masks[class_name].to(dtype=torch.int16)\n",
    "    \n",
    "            for class_name, class_mask in class_masks.items():\n",
    "                class_mask_np = class_mask.cpu().numpy()\n",
    "                image_name = image_filename + f'_{class_name}.tif'\n",
    "    \n",
    "                output_path = os.path.join(self.output_dir, class_name)\n",
    "                \n",
    "                os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "                Image.fromarray(class_mask_np.astype(np.uint16)).save(Path(output_path) / image_name)\n",
    "    \n",
    "    def modelPrep(self):\n",
    "        from detectron2 import model_zoo\n",
    "        from detectron2.engine import DefaultPredictor\n",
    "        from detectron2.config import get_cfg\n",
    "        \n",
    "        \n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training\n",
    "        cfg.MODEL.WEIGHTS = self.model_file\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  # Default is 512, using 256 for this dataset.\n",
    "        cfg.MODEL.DEVICE = 'cpu'\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # We have 200 classes.\n",
    "        cfg.TEST.DETECTIONS_PER_IMAGE = 300\n",
    "        cfg.MODEL.DEVICE = 'cpu'\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5# set a custom testing threshold\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "        return predictor\n",
    "    \n",
    "    def imgPrep(self):\n",
    "        im = np.stack([self.img,self.img,self.img])\n",
    "        return im.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "240c60900d2dd797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:40:11.549561Z",
     "start_time": "2025-03-06T18:40:11.543345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2MY\\Documents\\Uni Work\\Level 4\\TR-Y4-Project\\Research\\SavedSegs\\tiffPhaseSegs\n"
     ]
    }
   ],
   "source": [
    "tiffstack_path = r\"C:\\Users\\2MY\\Documents\\Uni Work\\Level 4\\TR-Y4-Project\\ImageRepo\\t_1_MMStack_Default_6.ome.tif\"\n",
    "model_path = r'C:\\Users\\2MY\\Documents\\Uni Work\\Level 4\\TR-Y4-Project\\Research\\SegModels\\model_final.pth'\n",
    "\n",
    "segDir = 'tiffPhaseSegs' \n",
    "# Name or version of your current output segmentation directory\n",
    "output_path = r'C:\\Users\\2MY\\Documents\\Uni Work\\Level 4\\TR-Y4-Project\\Research\\SavedSegs'\n",
    "output_path = os.path.join(output_path, segDir)\n",
    "my_seg = tiffSegmentation(model_path, tiffstack_path, output_path, output_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ef5155b827eca4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:41:48.748795Z",
     "start_time": "2025-03-06T18:40:44.465106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting image 5 / 107"
     ]
    }
   ],
   "source": [
    "my_seg.phaseSeg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce607ca13906d3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
